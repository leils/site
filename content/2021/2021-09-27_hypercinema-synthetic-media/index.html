<!DOCTYPE html>
<link rel="stylesheet" href="/bundle.css">
<html lang="en">
	<head>
		<meta charset="utf-8">
		<meta name="viewport" content="width=device-width, initial-scale=1.0">
		<title>Hypercinema - Synthetic Media</title>
	</head>
	<body>
        <div class="siteheader">
            <div class="heroline secrethint" id="heroline">~ lsc ~ this site is pre-fermenting* ~</div>
        </div>

		<div class="navigation">
			<a href="/">the work</a>
			<a href="/about">about</a>
			<a href="/everything-else">everything else</a>
			
		</div>
		  <div class="content-background">
  <div class="blogHeader">
    <h1>Hypercinema - Synthetic Media</h1>
    <hr>
    
      <picture><source type="image/webp" srcset="/content/2021/2021-09-27_hypercinema-synthetic-media/h-EwdTLd4a-1838.webp 1838w"><img alt="./deoldify-screenshot.png" src="/content/2021/2021-09-27_hypercinema-synthetic-media/h-EwdTLd4a-1838.jpeg" width="1838" height="1012"></picture>
    
  </div>
    <p>We talk a lot about deepfakes and generated media when it comes to synthetic media, but a subtler form of synthetic media is augmenting pre-existing media. Recently, videos like the ones below show an AI recolorization of old black-and-white films. This has been applied to videos taken candidly of people, to production videos of dances and entertainment, and to movies. The main re-colorizer that I've seen used is <a href="https://github.com/jantic/DeOldify">DeOldify</a> .</p>
<p><code>https://www.youtube.com/watch?v=hZ1OgQL9_Cw</code>
<code>https://www.youtube.com/watch?v=vif94mNX8Nk</code></p>
<p>I consider this to be synthetic media because it inherently generates net new information that is incorporated in the final form of the media. For the AI, there is no data on what colors were popular for clothing in this era, or how exactly they might have been portrayed through the black-and-white film. It simply sees black and white, and generates its best guess at what the color may have been. The model has been trained with data from <a href="https://image-net.org/">https://image-net.org</a>, a dataset of over 15 million images. The model has been fed black-and-white versions of those images, and then trained against the original color versions. One of the issues here is that the images have been converted to black-and-white through digital means, but there is no direct film-to-digital-color comparison being made. When all of the old black-and-white video was done on film, this seems like a bit of a missed opportunity (though an understandable one, considering how limited the data would be).</p>
<p>While colorization may seem like a minor detail, I think that representing the output of this ML model as &quot;truth&quot; is ethically fraught. Our current response to video media is to understand it as truth, something that Deep Fakes make us question. Faking color is another, subtler form of information creation, one that has its own biases and issues. Already we have issues with how the AI represents different skin colors and tones, something that shows the biases in its training data. How can we know whether the AI has colored a dress the way that it would have appeared in real life? How does it represent hair colors, eye colors, textures? These details change how we see the world, and making them up may leave us with the wrong impressions.</p>

  </div>
  <div class="blogFooter">
    <p> Posted/updated 2021-09-27 </p>

    
      <div class="pageTags">
        
        Tagged: 
        
           <a href="/tags/content">content</a>
          , <a href="/tags/itp">itp</a>
          , <a href="/tags/hypercinema">hypercinema</a>
      </div>
    
    
  </div>

		<hr>

		<div class="footer">
			<p>you can also find me on <a href="https://www.instagram.com/leia.make/">instagram</a> and <span id="findline" class="secrethint">offline elsewhere*</span>.</p>
			<a href="/absolutely-everything">appendix</a>
		</div>
		<dialog id="herodialog">
			<p>pre-fermenting: ingredients have been mixed, roughly stirred by hand, water and flour and the magic in the air, this will become something new and the change is rapid but we just have to wait to see when it'll be ready</p>
			<form method="dialog">
				<button id="heroCloseBtn">OK</button>
			</form>
		</dialog>

		<dialog id="finddialog">
			<p>* also found frequently in sunlight, on the pier, in the middle of it all, at a cafe table
			</p><form method="dialog">
				<button id="findCloseBtn">OK</button>
			</form>
		</dialog>

		<script>
			const heroline = document.getElementById("heroline");
			const herodialog = document.getElementById("herodialog");
			const herocloseBtn = document.getElementById("heroCloseBtn");

			heroline.addEventListener("click", () => {
				herodialog.showModal();
			});

			herocloseBtn.addEventListener("click", () => {
				herodialog.close();
			});

			const findline = document.getElementById("findline");
			const finddialog = document.getElementById("finddialog");
			const findCloseBtn = document.getElementById("findCloseBtn");

			findline.addEventListener("click", () => {
				finddialog.showModal();
			});

			findCloseBtn.addEventListener("click", () => {
				finddialog.close();
			});
		</script>

	</body>
</html>

<!doctype html>
<link rel="stylesheet" href="/bundle.css">
