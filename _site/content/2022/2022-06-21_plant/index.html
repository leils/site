<!DOCTYPE html>
<link rel="stylesheet" href="/bundle.css">
<html lang="en">
	<head>
		<meta charset="utf-8">
		<meta name="viewport" content="width=device-width, initial-scale=1.0">
		<title>p l a n t</title>
	</head>
	<body>
        <div class="siteheader">
            <div class="heroline secrethint" id="heroline">~ lsc ~ this site is pre-fermenting* ~</div>
        </div>

		<div class="navigation">
			<a href="/">the work</a>
			<a href="/more">& more</a>
			<a href="/about">about</a>
			<a href="/everything-else">everything else</a>
			
		</div>
		  <div class="content-background">
  <div class="blogHeader">
    <h1>p l a n t</h1>
    <hr>
    
      <picture><source type="image/webp" srcset="/.11ty/image/?src=content%2F2022%2F2022-06-21_plant%2FPlant-1.jpg&width=6720&format=webp&via=transform 6720w"><img alt="./Plant-1.jpg" src="/.11ty/image/?src=content%2F2022%2F2022-06-21_plant%2FPlant-1.jpg&width=6720&format=jpeg&via=transform" width="6720" height="4480"></picture>
    
  </div>
    <p><em>laser-cut ply // found materials // Arduino (Adafruit ESP32 Feather, Servos &amp; Multiplexer) // MaxMSP // Kinect Azure</em></p>
<p>p l a n t is a kinetic sculpture that recognizes and responds to the presence of viewers.</p>
<p><code>https://youtu.be/ctKftBH3xLM</code></p>
<p>This sculpture is set up to be unassuming, surrounded by other greenery. While at first it’s completely still, the leaves bend towards the viewer as they step closer. It was built to have no detectable sensors on the sculpture itself; instead, the piece leverages the natural disinclination to look up to hide a sensor directly overhead.</p>
<p><picture><source type="image/webp" srcset="/.11ty/image/?src=content%2F2022%2F2022-06-21_plant%2Fplant_overall.jpg&width=1500&format=webp&via=transform 1500w"><img src="/.11ty/image/?src=content%2F2022%2F2022-06-21_plant%2Fplant_overall.jpg&width=1500&format=jpeg&via=transform" alt="Image of a plant-like sculpture." width="1500" height="2000"></picture></p>
<p>The leaves on this sculpture are all laser-cut craft plywood, cut with kerf allowing for flexible movement with spring-like tension.</p>
<hr>
<h2>process</h2>
<p>p l a n t was originally created as a part of a themed entertainment exploration. The idea was to illustrate intelligent plant life; Plants that would recognize and follow you as you walked (or rode) past them.
In the proposed dark ride, these would be fabricated at various scales and be scattered through the scenes, adding to the illusion of an alien-like and hyper-intelligent environment.</p>
<p>This kinetic sculpture is made out of laser-cut ply, fishing wire, and an Arduino base. Other than the Arduino parts, everything is found or re-used materials (including the metal canister and the wood each leaf is cut from).</p>
<p><code>https://youtu.be/ctKftBH3xLM</code></p>
<ol>
<li>sketches/concept</li>
<li>motion and material tests</li>
<li>single leaf</li>
<li>mockup</li>
<li>MAX, Kinect, and OSC</li>
</ol>
<h3>SKETCHES</h3>
<p>This plant was conceptualized as a sculpture installed within a ride queue. As guests would walk up to and past the sculpture, the plant would reach toward them. This would bring the world-building of the ride out into the line, and entertain guests while they wait.</p>
<p><picture><source type="image/webp" srcset="/.11ty/image/?src=content%2F2022%2F2022-06-21_plant%2Fsketches.jpg&width=1517&format=webp&via=transform 1517w"><img src="/.11ty/image/?src=content%2F2022%2F2022-06-21_plant%2Fsketches.jpg&width=1517&format=jpeg&via=transform" alt="Sketches including birds-eye and side view of planned interaction with plant." width="1517" height="1100"></picture></p>
<h3>MOTION &amp; MATERIAL TESTS</h3>
<p>The first tests were done in paper. Inspired by the work of <a href="https://www.caseycurran.com">Casey Curran</a>  and <a href="https://wolfcatworkshop.com/index.php/portfolio/one-month-small-machines/">Wolfcat Workshop</a> , I explored using layered pieces of paper to get a complex, lifelike movement.</p>
<p><picture><source type="image/webp" srcset="/.11ty/image/?src=content%2F2022%2F2022-06-21_plant%2Fpaper-tests.jpg&width=2000&format=webp&via=transform 2000w"><img src="/.11ty/image/?src=content%2F2022%2F2022-06-21_plant%2Fpaper-tests.jpg&width=2000&format=jpeg&via=transform" alt="Layered paper for motion tests" width="2000" height="1500"></picture></p>
<p><code>https://youtube.com/watch?v=EEWEZEeWX1o</code></p>
<p>While these were satisfying in their own right, I wanted to see what this movement looked like with a more rigid material. The next step was to move into wood. I’d used kerf-cut wood to achieve bends before, but for pieces in motion. After a bit of experimentation, I put together a kerf pattern that allowed for enough give to move easily, but also could spring back to its original form when pressure was released.
The kerf cuts I started from can be <a href="https://www.troteclaser.com/en-us/learn-support/helpcenter/bending-technique">found here</a>.</p>
<p><picture><source type="image/webp" srcset="/.11ty/image/?src=content%2F2022%2F2022-06-21_plant%2FPlant-8.jpg&width=6720&format=webp&via=transform 6720w"><img src="/.11ty/image/?src=content%2F2022%2F2022-06-21_plant%2FPlant-8.jpg&width=6720&format=jpeg&via=transform" alt="Bending kerf-cut wooden leaf" width="6720" height="4480"></picture></p>
<p><code>https://youtube.com/watch?v=1qh9yFkGbc4</code></p>
<h3>A SINGLE LEAF</h3>
<p>After the leaf material and design were satisfactory, I put together a motorized test.
This allowed me to create a proof-of-concept for the moving plant. I connected a single servo to an ESP32 Feather, and controlled that motor via wifi.</p>
<p><code>https://youtube.com/watch?v=MM1_45ECQqQ</code></p>
<h3>MOCKUP</h3>
<p>After making a single leaf, I was able to duplicate it and tweak the design for easier assembly.</p>
<p>I then created a mock-up of the final piece in Fusion360 to get a rough idea of how it would be assembled. By modeling the single-leaf assembly, I was able to do a digital test-run on the spacing and housing requirements for the final piece.</p>
<p><picture><source type="image/webp" srcset="/.11ty/image/?src=content%2F2022%2F2022-06-21_plant%2Fmockup.png&width=1706&format=webp&via=transform 1706w"><img src="/.11ty/image/?src=content%2F2022%2F2022-06-21_plant%2Fmockup.png&width=1706&format=jpeg&via=transform" alt="Mockup of multi-leaf assembly in Fusion360" width="1706" height="1328"></picture></p>
<p>After the mock-up, I built 4 more leaves and wired them up to a servo multiplexer. After confirming that everything worked, I salvaged materials to create a pot-like housing.</p>
<p><code>https://youtu.be/rPrndz2n5tY</code></p>
<p><picture><source type="image/webp" srcset="/.11ty/image/?src=content%2F2022%2F2022-06-21_plant%2FPlant-6.jpg&width=6720&format=webp&via=transform 6720w"><img src="/.11ty/image/?src=content%2F2022%2F2022-06-21_plant%2FPlant-6.jpg&width=6720&format=jpeg&via=transform" alt="Internals of kinetic sculpture" width="6720" height="4480"></picture></p>
<h3>DETECTION</h3>
<p>Once I had the mechanical parts all set up, it was time to do the person detection.</p>
<p>For body detection, I used an overhead-mounted Kinect Azure and MaxMSP. Using DPKinect-V3, I grabbed the Kinect’s depth data, filtered it to a maximum of 1.4 meters, and ran it through CV Jitter to detect blobs. While technically I’m diff-ing this input to a base image, I don’t think this is actually necessary so long as no other objects are by default within the detection area.</p>
<p><picture><source type="image/webp" srcset="/.11ty/image/?src=content%2F2022%2F2022-06-21_plant%2Fmaxpatch.png&width=2958&format=webp&via=transform 2958w"><img src="/.11ty/image/?src=content%2F2022%2F2022-06-21_plant%2Fmaxpatch.png&width=2958&format=jpeg&via=transform" alt="Maxpatch" width="2958" height="2152"></picture></p>
<p>By then taking the centroids of the detected blobs, I could calculate what angle the blob appeared compared to the central point, and trigger the related servo.
My Max Project is available <a href="https://github.com/leils/spring_2022_theme_park_eng/tree/main/expedition-earth/interactive-plant/kinect-blob-to-servo">here on github</a>.</p>
<p>Control of the Arduino was done through OSC messages over WiFi, which I’ve used before in <a href="https://www.leiac.me/2022/2022-02-23_tpe-osc-control/">previous experiments</a>.</p>
<p><picture><source type="image/webp" srcset="/.11ty/image/?src=content%2F2022%2F2022-06-21_plant%2Fplant_cover.jpg&width=2000&format=webp&via=transform 2000w"><img src="/.11ty/image/?src=content%2F2022%2F2022-06-21_plant%2Fplant_cover.jpg&width=2000&format=jpeg&via=transform" alt="Picture of final kinetic plant" width="2000" height="1991"></picture></p>
<p>———————————————</p>
<h2>Takeaways:</h2>
<ul>
<li>CAD is an extremely useful tool when your work gets more complicated than a single-part assembly</li>
<li>Getting test data is always useful, especially when your sensor setup has special requirements (ie. being mounted to the ceiling)</li>
</ul>
<h3>Difficulties:</h3>
<ul>
<li>Sometimes Max would need to be re-started in order to fetch Kinect data</li>
<li>I did not take into account the cables running to the Arduino for power when designing the housing, and a right-angle power cable had to be found in order for everything to fit.</li>
</ul>
<p>Thanks to Scott Fitzgerald for all the help with Max.</p>

  </div>
  <div class="blogFooter">
    <p> Posted/updated 2022-06-21 </p>

    
      <div class="pageTags">
        
        Tagged: 
        
           <a href="/tags/content">content</a>
          , <a href="/tags/physical-computing">physical computing</a>
          , <a href="/tags/fabrication">fabrication</a>
          , <a href="/tags/itp">itp</a>
          , <a href="/tags/showcase">showcase</a>
          , <a href="/tags/interactive">interactive</a>
          , <a href="/tags/theme-park-eng">theme-park-eng</a>
      </div>
    
    
      <div class="pageTech">
        Tech: 
        
          , <a href="/tech/laser cutting">laser cutting</a>
          , <a href="/tech/Arduino">Arduino</a>
          , <a href="/tech/Max MSP">Max MSP</a>
          , <a href="/tech/Kinect">Kinect</a>
          , <a href="/tech/OSC">OSC</a>
      </div>
    
  </div>

		<hr>

		<div class="footer">
			<p>you can also <span id="findline" class="secrethint">find me*</span> on <a href="https://www.instagram.com/leia.make/">instagram</a> and <a href="https://github.com/leils">github</a>.</p>
			<a href="/absolutely-everything">appendix</a>
		</div>
		<dialog id="herodialog">
			<p>pre-fermenting: ingredients have been mixed, roughly stirred by hand, water and flour and the magic in the air, this will become something new and the change is rapid but we just have to wait to see when it'll be ready</p>
			<form method="dialog">
				<button id="heroCloseBtn">OK</button>
			</form>
		</dialog>

		<dialog id="finddialog">
			<p>* also found frequently in sunlight, on the pier, in the middle of it all, at a cafe table
			</p><form method="dialog">
				<button id="findCloseBtn">OK</button>
			</form>
		</dialog>

		<script>
			const heroline = document.getElementById("heroline");
			const herodialog = document.getElementById("herodialog");
			const herocloseBtn = document.getElementById("heroCloseBtn");

			heroline.addEventListener("click", () => {
				herodialog.showModal();
			});

			herocloseBtn.addEventListener("click", () => {
				herodialog.close();
			});

			const findline = document.getElementById("findline");
			const finddialog = document.getElementById("finddialog");
			const findCloseBtn = document.getElementById("findCloseBtn");

			findline.addEventListener("click", () => {
				finddialog.showModal();
			});

			findCloseBtn.addEventListener("click", () => {
				finddialog.close();
			});
		</script>

	</body>
</html>

<!doctype html>
<link rel="stylesheet" href="/bundle.css">
